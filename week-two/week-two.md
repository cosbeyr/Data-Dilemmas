### Thoughts on Secure and Accessible Design

“A Brief Introduction to Usable Security” does an excellent job introducing the ideas of usability, security and the relationship between the two. The authors explore the histories associated with user authentication and email encryption, highlighting designs throughout time and explaining their security vulnerabilities, usability short-comings and the details that led them to be successful. The case studies the authors present are informative and wide-ranging about the technologies that have been designed but I would have liked to gain more of an understanding of who the designers were in terms of background and why they approached these tasks in the way they did so as to better understand their shortcomings and victories. It is interesting to consider that in order for our technological systems to be successful, we need both security and usability; however, in traditional implementations these terms have been consistently at odds with one another. I know in my technology use I have not always taken every prescribed security measure, mostly out of inconvenience and I don’t think I’m alone in this. For example, I know several folks who, upon the initial deployment of password managers, religiously used them to store their passwords which, in turn, became a menacing force when they were required to log in or access information while in class or on a public machine. Even two-factor authentication can prove tiresome for a student trying to give a presentation in class. This makes me realize that passwords and encryption are universally needed security measures and not only exist within different types of technology but also within different groups of users (college students at a public university are only one to consider when tackling this problem space). It’s important as designers of technology that we consider a multitude of large- and small-scale communities that will make use of the technology.

It is obvious that obtaining the highest level of security can often lead to lessened usability and vice versa; this reminded me of the approaches suggested in “DesignX: Complex Sociotechnical Systems.” Along with the recommendation for modularity and decomposition, the authors celebrate the idea that “operations don’t have to be perfect: they simply need to be approximations to the desired end result, to be ‘good enough’” (Norman, 93). I think this idea is important when considering usability and security; if we focus too much of our attention on one, we lose sight of the other. It makes more sense to me that we focus on finding the middle ground between the two. I imagine a lot of the folks currently working in technology, primarily those that have come from CS and Engineering backgrounds, would argue for an uptick in security over usability but I firmly believe that decreased usability only increases the security risks. As was said in the DesignX publication, the “limited capability of humans to fully comprehend complex systems leads them naturally to the construction of systems that they can understand, even if imperfectly” (92). When considering an individual user making use of a provided security technology, I think this human characteristic, although in a different context, comes into play because they will ultimately use a tool they are given in a way that suits them rather than in the way it is intended to be used. This is why human-computer interaction is such an important component to any implementation, as designers and engineers we need to explore the multitude of ways that our product may be used by a community rather than build ridgid tools that only conform to one view of how something should be accomplished. 

When the authors of the usable security article mentioned that “computers grow ever faster (thus, cracking passwords becomes easier)” it made me think about the ways that technologists will need to respond to this increased threat (Payne, 14). Even though there is always the option to introduce a larger key space, that will clearly decrease the level of usability and in turn have the potential to reduce the overall security of the system. Later in the article, the authors suggest two primary approaches to fixing or overcoming issues: changes to the interface or reframing of the problem space. The former, obviously, can only be effective with smaller bugs whereas the latter has the potential to fix broader, more underlying issues. This idea of reframing or thinking from other perspectives is something that comes up often in HCI. I recently heard a story from a now HCI researcher about a class she took while in college; she was working to design an application for the blind and had a blind professor come to try it out. Her expectation was that it would work really well for him because she had tested it out herself by closing her eyes and trying to use it. When he tried it out and it was a failure, she realized the fault in her design process. The same applies to the password space; we cannot effectively build authentication if we do not understand the intentions of the end users.

The ideas from the theory of Actor-Networks (ATs), as discussed in “On Actor-Network Theory,” can be employed to help us rethink authentication and encryption. We can incorporate the social, cultural, political and economical factors brought up in the DesignX paper as actors “acting” on the engineers, designers and system users to better understand where the issues stem from. We can represent both the process of building the system as well as the deployed system in use. In terms of the specific issue of passwords, we would most likely find that there is not just one user actor -- we are likely to discover many different types of single users and groups of users all or some of whom may use the technology in different ways depending on their task at hand, background and technology literacy. I think this would be helpful to engineers too often stuck with how they would use the software they were designing and help them think outside of the box. I’m not sure what else should be represented with AT and how to complete the picture of what this space looks like but starting to think in this way and reconsider the actions of end users is important. I think that AT can act as a bridge from the STEM side of engineering to the social sciences side and bring us closer to the idea of “muddling through” from the DesignX paper.

---

Latour, Bruno. "On actor-network theory. A few clarifications plus more than a few complications." *Finn Olsen*, vol. 47, 1996, pp. 369-381.

Norman, Donald A., and Pieter Jan Stappers. "DesignX: Complex Sociotechnical Systems." *Tongji University Press*,  2015, pp. 83-106.

Payne, Bryan D., and W. Keith Edwards. "A Brief Introduction to Usable Security." *IEEE Computer Society*, vol. 8, 2008, pp. 13-21.

 

---
[Go Back](https://cosbeyr.github.io/Data-Dilemmas/)
