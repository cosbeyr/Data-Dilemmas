### Are You Designing This Security For Yourself?

Mickens’ article begins with an analogy that “security people … are full of
morbid and detailed monologues about the pervasive catastrophes that surround
us, but they are much less interested in the practical topic of what people
should do before we’re inevitably killed by ravens” (Mickens, 8). Although this
statement, like most of the article, was hyperbolic and convoluted, I think I
understand what Mickens is getting at. At the very least, his use of the word
“practical” sparked my interest. It is often easier for anyone in technology,
especially cyber security folks (from here on out referred to as “cyberists”),
to byte off more than they can chew instead of “muddling through” and focusing
on the smaller elements of the systems they are building that more directly and
consistently affect their userbase. I think Mickens’ point is specifically about
passwords and how little attention is being paid to them by experts even though,
when it comes to users, passwords are an integral security measure for every
user. This same critique of cyberists is echoed through both the Whitten and
Abu-Salma publications although the former focuses on PGP 5.0 and the latter on
“secure communication tools.”

Whitten’s article presented the findings from a study that tasked participants
with using PGP 5.0, the conclusion being that PGP 5.0 is unusable more of the
time than not. The description of the misuse by the participants was almost as
comical as Mickens’ article but moreover points to a lack of broad testing with
various user groups on the part of the PGP 5.0 developers. Whitten points out
that as designers, we “should not assume that users will be motivated to read
manuals or to go looking for security controls that are designed to be
unobtrusive” (Whitten, 3). This reminds me of one of last week’s readings which
critiqued divorcing control panel functionality from the main application. I
imagine it is difficult for a cyberist to put themselves in the shoes of anyone
who does not match their demographic or background, let alone someone
non-technical, but if you are designing technology for other people it is
important that you get a sense of how it will be used by your userbase. I agree
completely with Whitten’s central argument that “standard usability evaluation
methods, simplistically applied, may treat security functions as if they were
primary rather than secondary goals for the user” (14). This helps me to reframe
the issue: rather than twisting cyber security to conform to the preexisting
ideas of “usable technology,” we need to take a step back and see what role
security plays in the broader technology landscape. As both Whitten and
Abu-Salma point out, security plays second fiddle to whatever action the user is
attempting to complete (e.g. sending an email, visiting a website) which means
that what we consider as “usable” will look different.

This idea provides insight to Abu-Salma’s recommendation of including
“non-security information that users desire” on the EFF Secure Messaging
Scorecard because these types of information can “drive adoption” (Abu-Salma,
15). It reminds me of how whenever I have to give my dog medicine, I always hide
it in peanut butter. This suggestion by Abu-Salma is a tricky way to educate a
user on cyber security while giving them the other stats they care about. What
confuses me in this article is the idea that we can change the mental model of
the user. How would we achieve this? How ingrained are mental models? This makes
me think of the activity we did last week with the covid-19 contact tracing. As
I was reading my article about the NHS’ contact tracing implementation, I
momentarily forgot that our current situation was real and not just a
hypothetical. In that moment (which was almost blissful), my first thought was
that I would never ever download an app like this because I didn’t have a good
way to trust that my data wouldn’t be used by governments or corporate entities
to cause harm. This mental model that I possess is based on true information
about the current structures of our society. I imagine a non-technical user’s
skepticism, based less so on experience and more on what they hear about on the
evening news, would be an even more difficult mental model to shift than my own
towards data collection. I think a big factor in this regard will come with
time: as new generations grow up, they will (hopefully?) be more fluent in cyber
security and the ideas of encryption and E2E will be less overwhelming to them
because they will have grown up surrounded by technology.

The other sticking point for me that was brought up in both the Whitten and
Abu-Salma publications was the characterization of the user they were studying.
Whitten explains that the work was “focused on personal computer users who have
little initial understanding of security” rather than “corporate or military
users” (14). Abu-Salma states that their focus was on “users of communication
tools who do not consider themselves to be at risk of targeted surveillance”
unlike “activists, whistleblowers, or journalists” (4). The many types of users
exemplified in these statements points to various levels of understanding about
how cyber security works as well as various primary goals of the users in
question. I’m not positive that there can be one security solution that will
work with each user group because of these compounding factors. We cannot expect
someone at home to have received any professional literature on how to be secure
in the way that we might expect someone at work. And even then, it is provably
rare that a company will spend a lot of time worrying about their security until
a breach occurs and they are held fiscally responsible. From these articles, it
is clear that the current security tools in development are not designed for a
non-technical personal computer user. I think it is important that cyberists
begin with that colossal demographic because they are the bottom rung of the
security ladder. If Dana Boyd’s arguments around networked privacy ring true in
the security domain, then we must secure this lowest rung to ensure security for
the upper tiers. 


---


Abu-Salma et al. "Obstacles to the Adoption of Secure Communication Tools."
*IEEE Security and Privacy,* 2017, pp. 1-17.

Mickens, James. "This World of Ours." *USENIX,* 2014, pp. 8-11.

Whitten, Alma, and J. D. Tygar. "Why Johnny Can't Encrypt: A Usability
Evaluation of PGP 5.0." pp. 1-15.




---
[Go Back](https://cosbeyr.github.io/Data-Dilemmas/)
