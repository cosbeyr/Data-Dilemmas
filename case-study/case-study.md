### ABSTRACT

In 2010, Twitter gifted the Library of Congress a collection of every historical tweet dating back to Twitter’s creation in 2006. Additionally, they gave the Library permission to continue collecting all future tweet data. Unlike other collections curated by the Library, the Twitter Archive represented an unprecedented, holistic view of how humans communicate with one another and a source of data related to human life. After seven years of collection, the Library announced that they would shift their collection and sharing procedures; rather than collecting all incoming tweets, they focused their efforts to thematic or event-based tweets. This shift was the result of a growing and changing social media field and required the Library of Congress to reevaluate their collection methods of streaming data. The transitions that occurred both on Twitter and within the Library of Congress’ collection of Twitter data are examples of trends occurring in the technology and archivist fields throughout the past decade. Reviewing the evolution of social media platforms, advances in data storage and retrieval technologies as well as the distinct ways that data is collected and used by both archival and computational researchers can shed light on the direction, challenges and opportunities that will be encountered by communities focused on data collection. Throughout this work, we review the shared and individual ways that archivists and data scientists interact with social media data starting with an in-depth analysis of the actors and entities contributing to the Library of Congress’ collection efforts. We also identify the potential that exists for both data scientists and archivists in borrowing from each other’s protocols and motivations.


### BACKGROUND 

In 2010 the Library of Congress, one of the largest libraries in the world, announced that Twitter, a budding, five-year-running social media platform, had gifted them all historic and all future public tweets for digital archiving. This generous gift was like none they had received previously and marked the start of a new digital chapter. The Library is the oldest federal cultural institution in the United States and houses collections that contain a variety of data mediums including but not limited to books, recordings, photographs, newspapers and manuscripts. The collections “document the history and further the creativity of the American people and … record and contribute to the advancement of civilization and knowledge throughout the world.” In addition to developing these collections, the formal mission of the Library is to “acquire, organize, provide access to, maintain, secure, and preserve these collections” [1]. These collections serve as a source of information for researchers and archivists from many disciplines spanning the public and private sectors. 

The Twitter Archive was not the first digital medium to arrive at the Library. Since 2000 the Library’s Web Archiving program has been in place to preserve digital online content [2]. Historically, two popular approaches to collecting data from the web have included bulk/domain harvesting and selective harvesting. With the Library’s web collection, they chose to employ the latter; websites of national and historic interest covering a wide variety of topics are preserved. Over the past two decades, by way of a contract with the Internet Archive, this large-scale web crawling effort has amounted to two petabytes of content. Beyond the collection and the transfer of this data, this web archive has required the Library to consider how to manage data of this volume and the underlying infrastructure to support it. 

Unlike previous digital collection projects, the proposed Twitter Archive would include all public tweets rather than a selection and would be the first “stream” content to be collected by the Library. The Library explained that the aggregate of all tweets “can be a resource for future generations to understand life in the 21st century” and pointed to the importance in saving “communication, news reporting and social trends” [3]. In 2010 the agreement made between the Library of Congress and Twitter ensured that only public tweets and no deleted or private tweets would be included in the archive. They specified that only text would be collected, excluding images, videos or linked content. The third caveat was that a buffer of six months would exist from when a tweet was first published and when the Library would be able to access it. Given the differences between this data, both format as well as amount intended to be collected, it was clear from the start that a different approach would be needed in order to manage and distribute access to this data. The Library stated that “the Twitter collection will serve as a helpful case study as we develop policies for research use of our digital archives” [3]. 


### COLLECTION OF TWEETS

In 2013 the Library announced that they had finalized their preservation of all historical tweets which included tweets made from 2006 through 2010. The Library restated the benefit of the collection in saying that “archiving and preserving outlets such as Twitter will enable future researchers access to a fuller picture of today's cultural norms, dialogue, trends and events to inform scholarship, the legislative process, new works of authorship, education and other purposes.” This five-year archive included 20 terabytes of data and amounted to 21 billion tweets. The next task the Library undertook was to “establish a secure, sustainable process for receiving and preserving a daily, ongoing stream of tweets … and to create a structure for organizing the entire archive by date.” The Library chose to use Gnip, a social media API aggregation company, as the designated delivery agent for the Twitter data. The tweets were organized into hour-long segments and uploaded to a secure server for retrieval by the Library. After the collection, files were to be copied to “two tape archives in geographically different locations as a preservation and security measure” [4].  

The announcement also stated the Library’s next task in brainstorming the best ways to make the collection accessible to researchers. Even though they had yet to release the archive to the public, they explained that they had already received more than 400 requests for access. The Library estimated that a single query of the 2006-10 archive, as it was currently stored, could take upwards of 24 hours to return results which would make it difficult for many researchers to take advantage of the collection. In addressing this issue, the Library pointed out that “to achieve a significant reduction of search time … would require an extensive infrastructure of hundreds if not thousands of servers” and explained that “this is cost-prohibitive and impractical for a public institution.” Both the funding available to this government institution as well as the limited time available in tackling this specific collection as it is one of the many curated by the Library contributed to the Library’s choice to explore other avenues. 

They stated that these other avenues may include public-private partnerships or the leveraging of private sector investment and capacity. The Library of Congress and Gnip specifically were exploring “the possibility of developing a research- and scholarship-focused interface to the archive using Gnip’s existing historical Twitter product offerings” [4]. The Library, in 2013 at least, was overall optimistic about the storage and access system they could develop for the Twitter Archive as well as about the potential use it could have for researchers and scientists.

In 2017, when the Library made their final announcement to date on the state of the Twitter Archive, the outlook was less optimistic than it had been previously. The Library decided to only selectively collect tweets, as they do with the web archive, and stated that “the tweets collected and archived will be thematic and event-based” [5]. They made this decision because of the volume of tweets that had been made since the agreement had been signed as well the increased use of images, videos and linked content, none of which was being collected by the Library. At this point in time the Library decided to refocus their collection efforts. All previously collected tweets would make up a snapshot showcasing the first twelve years of Twitter’s existence as a social media platform. Going forward, they decided to steer the Twitter archive closer to the Library’s general collection policies which are selective in nature, only preserving information that will be relevant to future generations. The Library also explained in the announcement that access to the preserved Twitter archive would be indefinitely halted; citing issues with tweets that had been deleted or made private after the collection and preservation. Since this announcement was made, the Library has yet to release the collection to the public and there are currently no engineers assigned to the project meaning that data continues to be collected but remains unprocessed or preserved. 


### Social Media Presence

Twitter was developed and launched in 2006. Five years later, users of the platform were generating 55 million tweets per day, in 2020 that number increased to 500 million tweets per day. Twitter is considered a “microblogging and social networking service on which users post and interact with messages known as ‘tweets.’” In 2010 Twitter introduced the capability of embedding pictures and videos into tweets themselves rather than redirecting a user to another webpage and in 2017 Twitter increased the character restriction from 140 to 280 characters per tweet. Both updates contributed to the Library’s decision to halt full collection of the data from the website. Throughout the fifteen years of its existence as a social media platform, Twitter Inc. has acquired startups and companies including application developers, search engines and advertising firms among others in order to increase the capability of the platform. Interestingly, in 2014, in parallel with the Library of Congress’ collection efforts, Twitter bought Gnip, the social media API service. This purchase has since allowed Twitter to control and profit from the collection efforts of tweets and other Twitter metadata. 


---

# WORKS CITED
[1] Library of Congress. “About the Library.” https://www.loc.gov/about/

[2] Library of Congress. “Web Archiving: About This Program.” https://www.loc.gov/programs/web-archiving/

[3] Raymond, Matt. “The Library and Twitter: An FAQ.” 2010. https://blogs.loc.gov/loc/2010/04/the-library-and-twitter-an-faq/

[4] Osterberg, Gayle. “Update on the Twitter Archive at the Library of Congress.” 2013. https://blogs.loc.gov/loc/2013/01/update-on-the-twitter-archive-at-the-library-of-congress/

[5] Osterberg, Gayle. “Update on the Twitter Archive at the Library of Congress.” 2017. https://blogs.loc.gov/loc/2017/12/update-on-the-twitter-archive-at-the-library-of-congress-2/


