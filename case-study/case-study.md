> #### ABSTRACT 
>
> Over the past two decades social media platforms have become an integral part in the daily lives of many Americans. Within a shared time frame the collection and understanding of social media data has grown in popularity within many communities. These communities include scientific researchers, social scientists, and industrialists spanning the public and private sectors with vastly differing motivations. One such party, the Library of Congress, publicized their collection efforts of Twitter data from 2010 through 2017.  The process and outcome of this data collection was affected by shifts in social media use and required the Library of Congress to rethink their collection methods of streaming data. This example points to the need for further analysis of the relationships between companies that run social media platforms and data collectors as well as an evaluation of the data’s content and what can be ethically concluded with it. In reviewing the shared evolution of the data collection process, social media platforms themselves and the interpretation of digital communication, we can better understand the challenges and opportunities that will be encountered by data collectors in the years to come.

#### BACKGROUND 

In 2010 the Library of Congress, one of the largest libraries in the world, announced that Twitter, a budding, five-year-running social media platform, had gifted them all historic and all future public tweets for digital archiving. This generous gift was like none they had received previously and marked the start of a new digital chapter for the Library. The Library is the oldest federal cultural institution in the United States and houses a variety of data mediums such as books, recordings, photographs, newspapers and manuscripts. The Library’s collections “document the history and further the creativity of the American people and … record and contribute to the advancement of civilization and knowledge throughout the world.” The formal mission of the Library is to “acquire, organize, provide access to, maintain, secure, and preserve these collections” which serve as a source of information for researchers and archivists from many disciplines spanning the public and private sectors [1]. 

The Twitter Archive was not the first digital medium to arrive at the Library. Since 2000 the Library’s Web Archiving program has been in place to preserve digital online content [2]. Historically, two popular web data collection approaches have included bulk/domain harvesting and selective harvesting. With the Library’s web collection, they chose to employ the latter; websites of national and historic interest covering a wide variety of topics are preserved. These themes and events serve as snapshots of human life during the timeframe of their collection. Over the past two decades, by way of a contract with the Internet Archive, this large-scale web crawling effort has amounted to two petabytes of content. Beyond the collection and the transfer of this data, this web archive has required the Library to consider how to manage data of this volume and the underlying infrastructure to support it. 

Unlike previous digital collection projects, the proposed Twitter Archive was to include all public tweets rather than a selection and would be the first “stream” content to be collected by the Library. The Library explained that the aggregate of all tweets “can be a resource for future generations to understand life in the 21st century” and pointed to the importance in saving “communication, news reporting and social trends” [3]. In 2010 the agreement made between the Library of Congress and Twitter ensured that only public tweets and no deleted or private tweets would be included in the archive. They specified that only tweet text would be collected, excluding images, videos or linked content as well as any other user account or profile information. The third caveat was that a buffer of six months would exist from when a tweet was first published and when the Library would be able to access it. Given the differences between this data and the Web Archive data, both in terms of format as well as the amount of data intended to be collected, it was clear from the start that a different approach would be needed in order to manage and distribute access. The Library stated that “the Twitter collection will serve as a helpful case study as we develop policies for research use of our digital archives” [3]. Although in 2010 the Library did not expand on what types of policies they hoped to develop, given the amount of data to be collected in the long term as well as the personal nature of the content collected, it is obvious that the Library would need to develop secure and efficient storage protocols as well as procedure to ensure that the data would be used responsibly. 

#### COLLECTION OF TWEETS

In 2013 the Library announced that they had finalized their preservation of all historical tweets  from 2006 through 2010. The Library restated the benefit of the collection in saying that “archiving and preserving outlets such as Twitter will enable future researchers access to a fuller picture of today's cultural norms, dialogue, trends and events to inform scholarship, the legislative process, new works of authorship, education and other purposes.” This five-year archive included 20 terabytes of data and amounted to 21 billion tweets. The next task the Library undertook was to “establish a secure, sustainable process for receiving and preserving a daily, ongoing stream of tweets … and to create a structure for organizing the entire archive by date.” The Library chose to work with Gnip, a social media API aggregation company, as the designated delivery agent for the Twitter data. The tweets were organized into hour-long segments and uploaded to a secure server for retrieval by the Library. After the collection, files were to be copied to “two tape archives in geographically different locations as a preservation and security measure” [4].  

The announcement also stated the Library’s next task in brainstorming the best ways to make the collection accessible to researchers. By ‘accessible’ the Library was interested in allowing users of the Twitter Archive to search for keywords in order to build subsets of tweets to answer research questions. Even though they had yet to release the archive to the public, they explained that they had already received more than 400 requests for access. These requests came from researchers interested in a range of topics from “[finding] patterns in the rise of citizen journalism and elected officials’ communications to tracking vaccination rates and predicting stock market activity.” The Library estimated that a single query of the 2006-10 archive, as it was currently stored, could take upwards of 24 hours to return results which would make it difficult for many researchers to take advantage of the collection. In addressing this issue, the Library pointed out that significantly reducing search time “would require an extensive infrastructure of hundreds if not thousands of servers” and explained that “this is cost-prohibitive and impractical for a public institution” [4]. 

Both the funding available to this government institution as well as the limited time available in tackling this specific collection, as it is one of the many curated by the Library, contributed to the Library’s choice to explore alternatives. They stated that these alternatives may include public-private partnerships or the leveraging of private sector investment and capacity. The Library of Congress and Gnip specifically were exploring “the possibility of developing a research- and scholarship-focused interface to the archive using Gnip’s existing historical Twitter product offerings” although this endeavor never came to fruition [4]. The Library, in 2013 at least, was optimistic about the storage and access system they could develop for the Twitter Archive as well as the potential use it could have for researchers and scientists. 
In 2017, when the Library made their final announcement on the state of the Twitter Archive, the outlook was less optimistic than it had been previously. The Library decided to collect tweets selectively, as they had previously decided with the Web Archive, and stated that “the tweets collected and archived will be thematic and event-based” [5]. In the time since the agreement had been originally made, the volume of the tweets had severely grown and it was becoming more common for tweets to contain linked content which was not collected by the Library. These factors drove the Library to refocus their collection efforts. All previously collected tweets would make up a snapshot showcasing the first twelve years of Twitter’s existence as a social media platform. Going forward, they decided to steer the Twitter archive closer to the Library’s general collection policies which are selective in nature, only preserving information that will be relevant to future generations. In the time since the announcement was made, the Library has not disclosed the selection of national themes or events they have collected so far or the process they have employed to do so. 

The Library also explained in the announcement that access to the preserved Twitter archive would be indefinitely halted; citing privacy issues with tweets that had been deleted or made private after collection by the Library. The Library has yet to release the collection to the public and there are currently no engineers assigned to the project. Although the collection efforts have apparently continued since the time of this announcement, the data collected is not likely being processed or actively preserved. The Library of Congress’ Twitter Archive is an example of a big data collection; although ultimately unsuccessful, this example points to two main areas for consideration and further inquiry: collaboration and content. Namely, collaboration with private companies such as Twitter and the effect differing motivations can have on the partnership. Content referring to a look at the nature of the data being collected and an evaluation of how it can be or use or disuse to various communities.

#### SOCIAL MEDIA AND SOCIETY

Twitter was developed and launched in 2006. Five years later, users of the platform were generating 55 million tweets per day; in 2020 that number increased to 500 million tweets per day. Twitter’s stated purpose is to “provide a light-weight, easy form of communication that enables users to broadcast and share information about their activities, opinions and status” [6]. This is likely what initially excited the Library of Congress about the prospect of a Twitter Archive. In 2010 Twitter introduced the capability of embedding pictures and videos into tweets themselves rather than redirecting a user to another webpage which encouraged users to remain on the platform. In 2017 Twitter increased the character restriction from 140 to 280 characters per tweet allowing users to share longer-form ideas. The increased user activity as well as the updates made to the appearance and content of the tweets contributed to the Library’s decision to halt full collection of the data from the website. It also points to a shift in the way humans communicate on social media platforms. 

Twitter is one of many social media platforms to grow in popularity within the past twenty years. Social networking sites such as Twitter and Facebook “promote interpersonal contact, whether between individuals or groups; they forge personal, professional, or geographical connections.” Platforms like Twitter proclaim their intentions to be focused on bringing people together over the Internet; however, there is much to glean about humans and how to profit from them with the data generated by the users of these websites. The mining of user’s data from a social platform by the platform itself has likely influenced the ways those same users interact with the platform in the time to come. van Dijck explains that these platforms “utilize their data to influence traffic and monetize engineered streams of information” [7]. An example can be seen in the 2012 emotion experiment conducted by Facebook in which the content displayed to nearly seven thousand users was manipulated by Facebook employees in order to understand the impact of negative social feeds [8]. As social media platforms are for profit and run by private corporations it is easy to look beyond their altruism to their underlying unethical and exploitive nature.

Given the Library of Congress’ Twitter archive, the question centers on what Twitter had to gain from the collaboration. In 2014, in parallel with the Library’s collection efforts, Twitter bought Gnip, the social media API service used by the Library for tweet collection. This purchase allowed Twitter to take control and profit from the collection efforts of tweets and other Twitter metadata. This is a probable explanation of why nothing came from the Library’s wish to utilize more of Gnip’s capabilities and expand on their private partnership. The same researchers that expressed interest in having a Twitter Archive freely available from the Library of Congress have likely paid for access to Twitter data in the years since the Library’s halted collection efforts. Twitter’s purchase of Gnip and subsequent selling of data combined with the known limitations of a publicly funded entity such as the Library of Congress have made their gift to the Library more of a publicity stunt than an act of good doing. Twitter’s ability to collect, store and access their own data have and will always exceed that of the Library. Even the Library of Congress’ narrowing of collection to selective tweets has not resulted in a publicly available archive. Although the Library has expressed interest in partnering with private entities possessing the storage and access capabilities they seek, no further agreements have been made which speaks to the private sector’s unwillingness to take action unless it will financially benefit them.

#### THE DATA ITSELF

Data mined from social media platforms grows every minute as more interactions occur between users. Beyond the technological aptitude required for the collection, storage and access of large amounts of data, a second question concerns the content of the data and the quality or type of research that can be conducted with it. 

---

#### WORKS CITED
[1] Library of Congress. “About the Library.” https://www.loc.gov/about/

[2] Library of Congress. “Web Archiving: About This Program.” https://www.loc.gov/programs/web-archiving/

[3] Raymond, Matt. “The Library and Twitter: An FAQ.” 2010. https://blogs.loc.gov/loc/2010/04/the-library-and-twitter-an-faq/

[4] Osterberg, Gayle. “Update on the Twitter Archive at the Library of Congress.” 2013. https://blogs.loc.gov/loc/2013/01/update-on-the-twitter-archive-at-the-library-of-congress/

[5] Osterberg, Gayle. “Update on the Twitter Archive at the Library of Congress.” 2017. https://blogs.loc.gov/loc/2017/12/update-on-the-twitter-archive-at-the-library-of-congress-2/

[6] Java et al. “We We Twitter: Understanding Microblogging Usage and Communities.” *ACM,* 2007.

[7] van Dijck, Jose. “The Culture of Connectivity: A Critical History of Social Media.” *Oxford University Press,* 2013. 

[8] “Facebook emotion experiment sparks criticism.” *BBC News,* 2014. https://www.bbc.com/news/technology-28051930

